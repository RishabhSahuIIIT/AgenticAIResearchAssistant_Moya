{
  "filename": "software-cost-estimation-models-and-techniques-a-survey-IJERTV3IS20384.pdf",
  "text": " \n \nAbstract— Software products are said to be feasible if they are \ndeveloped within the budget constraints. Prior to making software \nproduct it’s imperative to predict the software development cost. \nPractitioners have expressed concern over their inability to \naccurately estimate costs associated with software development. \nThis concern has become even more pressing as costs associated \nwith development continue to increase. As a result, considerable \nresearch attention is now directed at gaining a better \nunderstanding of evaluating software cost estimating tools. This \npaper summarizes software cost estimation models: COCOMO II, \nCOCOMO, PUTNAM, STEER and ESTIMACS based on the \nparameters implement ability, extensibility, flexibility and \ntraceability and techniques used to estimate software costs. \n \nIndex Terms— Software Cost Estimation Model, Software \nDevelopment, Software Development Cost, Development Life \nCycle, KLOC (Kilo Lines of Code), function count (FC), S/w \n(Software), KDSI (Kilo Delivered Source of Instruction), AT \n(Algorithmic Technique), NAT (Non-Algorithmic Technique) \n \nI. INTRODUCTION \nSoftware cost estimation model is an indirect measure, which is \nused by software personnel to predict the cost of a project. They \nare used for the number of purposes. It includes: \n \n \nBudgeting \n\nOverall estimate has to be accurate, the most desired \ncapability. Hence initial efforts are directed in \npredicting budget for the software product. \n\n \nTradeoff and risk analysis \n\nAn important additional capability is to illuminate the \ncost and schedule sensitivities of software project \ndecisions (scoping, staffing, tools, reuse, etc.). \n\n \nProject planning and control \n\nAn additional potential is to provide cost and schedule \nbreakdowns by component, stage and activity. \n\n \nSoftware improvement investment analysis Strategies \nsuch as tools, reuse, and process maturity benefit the \ndevelopment process of software.[1] \n \nThis paper has been divided into five sections. Initial being \nIntroduction, Section II pertains to surveying of various Cost  \n \n \n \nEstimation Models. Section III regards to surveying distinct cost \nestimation techniques. Section IV defines comparative analysis \nof various models on the basis of certain parameters. Finally, \nSection V summarizes and tells about future scope for the same. \nSection VI is References. \n\nII. \nCOST ESTIMATION MODELS  \n \nEconomy of s/w development would reduce the current \ndifficulties of software production resulting in cost overruns or \neven project cancellations. Just like in any other field, the field \nof software engineering cost models has had its own pitfalls. The \nfast changing nature of software development has made it very \ndifficult to develop parametric models that yield high accuracy \nfor software development in all domains. S/w development costs \nhikes abnormally and practitioners continually express reckon \nover their incapability to accurately predict the costs involved. \nS/w models constructively explain the development life-cycle \nand accurately predict the cost of developing a software product \n[2]. Many s/w estimation models have evolved in the last two \ndecades based on the pioneering efforts by the researchers. \nMostly being proprietary models cannot be compared and \ncontrasted as far as the model structure is concerned [3]. Theory \nor experimentation determines the functional form of these \nmodels. These are: \n \n1. COCOMO 81 \n \n1(a) Basic COCOMO \n \nCOCOMO is an acronym used for Constructive Cost Model. It \nwas first published in 1981 book Software Engineering \nEconomics by Barry Boehm. It gives the magnitude of cost of \nproject due to the ease of openness of model. It is meant for \nrelatively small projects as a very few cost drivers are associated \nwith it. Its supportive when the team size is small, i.e. small staff. \nIt’s good for quick, early, rough, order of magnitude of \nsoftware costs, but its accuracy is necessarily limited because of \nits lack of factors to account for difference in hardware \nconstraints, personnel quality and experience, use of modern \ntools and techniques and other project attributes are known to \nSoftware Cost Estimation Models and \nTechniques: A Survey \n1Yansi Keim, 1Manish Bhardwaj, 2Shashank Saroop, 2Aditya Tandon \n Department of Information Technology \nCh. Brahm Prakash Government Engineering College, Jaffarpur, New Delhi-110073 \n  \n1763\nInternational Journal of Engineering Research & Technology (IJERT)\nVol. 3 Issue 2, February - 2014\nIJERT\nIJERT\nISSN: 2278-0181\nwww.ijert.org\nIJERTV3IS20384\n\n\n \n  \n                                                                                                                                                          \nhave a significant influence on s/w costs. \n \nEFFORT = a* (KDSI)b \n \nThe value of constants a & b depend on the project type. The \nestimated number of delivered lines of code for the project \naccounts for the KLOC. \n \nBasic COCOMO has three types of modes which are following \n[4]:- \n \nOrganic Mode: Relatively small, simple s/w project in which a \nsmall teams with good application experience. Efforts, E and \nDevelopment, D are:- \n \nE = \n2.4*(KLOC)1.05 \nD=2.5*(E)0.38  \n \nSemi-detached Mode: An intermediate s/w projects in which \nteams with mixed experience \n \nE = 3.0* (KLOC)1.12 \n \nD=2.5*(E)0.35 \n \nEmbedded Mode: A s/w project that must be developed within \na set of tight h/w, s/w and operational constraints \n \nE = 3.6* (KLOC)1.20 \n \nD=2.5*(E)0.32 \n \n \n1(b) Intermediate COCOMO \n \nIt evaluates software development effort as a function of \nprogram size and set of cost drivers that include subjective \nexamination of the products, hardware, personnel and project \nattributes. \n \nIt is used for medium sized projects. The cost drivers are \nintermediate to basic and advanced COCOMO. Product \nreliability, database size, execution and storage are function of \ncost drivers. Team size is medium. The intermediate COCOMO \nmodel takes the form: \n \nEFFORT = a* (KLOC) b * EAF \n \nHere effort in person-months and KLOC is the estimated number \nof delivered lines of code for the project. \n \n1(c) Detailed COCOMO \n \nIt is used for large sized projects. Requirements, analysis, \ndesign, testing and maintenance determines the cost drivers, \nhere. Team size is large. The detailed COCOMO Model \ninculcates all features of the intermediate version with an \nassessment of the cost driver’s effect on each step (analysis, \ndesign, etc) of the software engineering process. \n \n2.  COCOMO-II \n \nThe COCOMO II research effort was started in 1994 at USC. Its \nmajor focus on non-sequential and rapid development process \nmodels, reengineering, reuse driven approaches, object oriented \napproaches, etc. It is a cumulative result of three variants, \nApplication composition model, Early design model, and Post \narchitecture model [5]. \n \na. The Application Composition model is worn to \napproximate effort and schedule on projects that use \nIntegrated Computer Aided Software Engineering tools \nfor rapid application development. It is based on Object \nPoints (Object Points are a tally of the screens, reports \nand 3 GL language modules developed in the \napplication).  \n \nb. The Early Design Model involves the investigation of \nsubstitute system architectures and concepts of \noperation.  \n \nc. \nThe Post-Architecture Model is used when apex level \ndesign is complete and thorough information about the \nproject is accessible and as the name suggests, the \nsoftware architecture is sound defined and well-known. \nIt accounts for the intact development life-cycle and is a \nexhaustive extension of the Early-Design model. This is \na lean-to intermediate COCOMO model and defined as:-  \n \nEFFORT = 2.9 (KLOC)1.10 \n \n \n3. PUTNAM MODEL (SLIM) \n \nSLIM (Software Life Cycle Model) is based on Putnam’s \nstudy in terms of Rayleigh distribution of project personnel level \nversus time. It chains most of the popular size estimating \nmethods including ballpark techniques, source instructions, \nfunction points, etc. It estimates project effort, schedule and \ndefect rate. Record and analyze data from formerly completed \nprojects which are then used to standardize the model [3]. If data \nare not obtainable then a set of questions can be answered to get \nvalues of MBI and PF from the presented database. \nProductivity, P, is the ratio of software product size S and \ndevelopment effort E is \nthat is \nP=  \n \n \n \nThe Rayleigh curve [2] is accustomed to define the distribution \nof effort which is modeled by the differential Equation \n \n \n \n \n \n \n1764\nInternational Journal of Engineering Research & Technology (IJERT)\nVol. 3 Issue 2, February - 2014\nIJERT\nIJERT\nISSN: 2278-0181\nwww.ijert.org\nIJERTV3IS20384\n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFig. 1: The Rayleigh Model \n \n4. ESTIMACS \n \nIt is a proprietary system which is used in critical flight s/w [7] \nand was marketed by Management and Computer Services \n(MACS). ESTIMACS stresses impending the evaluating task in \nbusiness terms. Rubin has recognized six vital proportions of \nestimation and a map presenting their interactions, all the way \nfrom what he calls the gross business terms through to their \nimpact on the developer’s protracted term projected portfolio \nmix. [3]The significant estimation dimensions are: effort hours, \n \na. staff size and deployment,  \nb. cost,  \nc. hardware resource requirements,  \nd. risk,  \ne. portfolio impact..  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFig. 2: Rubin’s map of relationship of estimation dimensions \n \n5.SEER-SEM \n \nSEER-SEM is System Evaluation and Estimation of Resources, \na product offered by Galorath, Inc. of El Segundo, California. \nThis model is based on the original Jensen model [Jensen1983], \nand has been on the market since last 15 years. The scope of the \nmodel is broad. It covers all phases of the project life-cycle, \nfrom early specification all the way through design, \ndevelopment, delivery and maintenance. It facilitates extensive \nsensitivity and trade-off analyses on model input parameters. It \norganizes project elements into work breakdown structures for \nsuitable planning and control and displays project cost drivers. \nThe model allows the interactive scheduling of project elements \non Gantt charts. Builds estimates upon a sizable information \nbase of existing projects [2]. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nIII. \nCOST ESTIMATION TECHNIQUES  \n \n \n \n \n \n \n \n \n \n \n \nA.  Algorithmic Techniques \n \nAlgorithmic methods use a formula to calculate the software cost \nestimate. The formula is developed from models which are \ncreated by combining related cost factors. In addition, the \nstatistical method is used for model construction. \n \nThe algorithmic method is designed to provide some \nmathematical equations to perform software estimation. These \nmathematical equations are based on research and historical data \nand use inputs such as Source Lines of Code (SLOC), number of \nfunctions to perform, and other cost drivers such as language, \ndesign methodology, skill-levels, risk assessments, etc. The \nalgorithmic methods have been largely studied and many models \n1765\nInternational Journal of Engineering Research & Technology (IJERT)\nVol. 3 Issue 2, February - 2014\nIJERT\nIJERT\nISSN: 2278-0181\nwww.ijert.org\nIJERTV3IS20384\n\n\n \n  \n                                                                                                                                                          \nhave been developed, such as COCOMO models, Putnam \nmodel, and function points based models. \n \nFunction Point Analysis \n \nThe Function Point Analysis is another method of quantifying \nthe size and complexity of a software system in terms of the \nfunctions that the systems deliver to the user. A number of \nproprietary models for cost estimation have adopted a function \npoint type of approach, such as ESTIMACS and SPQR/20. \nThis is a measurement based on the functionality of the program \nand was first introduced by Albrecht [8]. The total number of \nfunction points depends on the counts of distinct (in terms of \nformat or processing logic) types. \n \nThere are two steps in counting function points: \n \ni. \nCounting the user functions:- The raw function counts are \narrived at by considering a linear combination of five \nbasic software components: external inputs, external \noutputs, external inquiries, logic internal files, and \nexternal interfaces, each at one of three complexity \nlevels: simple, average or complex. The sum of these \nnumbers, weighted according to the complexity level, is \nthe number of function counts (FC).  \n \nii. \nAdjusting for environmental processing complexity:- The \nfinal function points is arrived at by multiplying FC by an \nadjustment factor that is determined by considering 14 \naspects of processing complexity.  \n \nB. Non-Algorithmic Techniques  \n \nNon-algorithmic methods do not use a formula to calculate the \nsoftware cost estimate. \n \ni. Top-Down Estimating Method \n \nTop-down estimating method is also called Macro Model. Using \ntop-down estimating method, an overall cost estimation for the \nproject is derived from the global properties of the software \nproject, and then the project is partitioned into various low-level \nmechanism or components. The leading method using this \napproach is Putnam model. This method is more applicable to \nearly cost estimation when only global properties are known. In \nthe early phases of the software development, it is very useful \nbecause there is no detailed information available. \n \nii. Bottom-Up Estimating Method \n \nUsing bottom-up estimating method, the cost of each software \ncomponents is estimated and then combines the results to arrive \nat an estimated cost of overall project. It aims at constructing the \nestimate of a system from the knowledge accumulated about the \nsmall software components and the interactions. The leading \nmethod using this approach is COCOMO's detailed model. \n \niii. Estimating by Analogy \n \nEstimating by analogy means comparing the proposed project to \npreviously completed similar project where the project \ndevelopment information id known. Actual data from the \ncompleted projects are extrapolated to estimate the proposed \nproject. This method can be used either at system-level or at the \ncomponent-levels. \n \nThe estimating steps using this method are as follows: \n \na. Find out the characteristics of the proposed project.  \n \nb. Select the most similar completed projects whose \ncharacteristics have been stored in the historical data base.  \n \nc. Find out the estimate for the proposed project from the most \nsimilar completed project by analogy.  \n \nIV.  \nCOMPARATIVE ANALYSIS OF VARIOUS \n \nMODELS ON THE BASIS OF CERTAIN \n   \nPARAMETERS \n \nCOCOMO 81 or COCOMO I model published in 1981. In [2], \nBarry Boehm described the capabilities of COCOMO 81 from \nsimply providing cost estimation capability to sensitivity \nanalysis and trade-off analysis. The reports in [3] tell us the \nmodel being entirely transparent; its openness shows how it \nworks. The drivers are helpful to understand the factors \naffecting project costs. However the shifting needs from \nmainframe overnight batch processing to real time application, \nstrenuous effort in building s/w for reusing, new system \ndevelopment including the off-the-shelf component, spending \nas much effort on designing, managing the s/w software \ndevelopment process once spent creating the s/w product, \napplication generation programs, object oriented approaches. \nThe model’s success greatly requires historical data, but it \nmight not be present every time. The COCOMO-II came into \nexistence [2] when needs mentioned above arose. Joint efforts \nof USC-CSE (University of California, Center for Software \nEngineering) and the COCOMO II Project Affiliate \nOrganizations the COCOMO II model was presented in 1995. \nIt supported updated project database [7]. The strategy \nmaintained focused upon preserving the openness of previous \nversion. \n \nSLIM s/w cost estimation model has not been widely accepted \ndue to certain limitations. Why it has been initially accepted is \ngiven below: One of the key advantages to this model is the \n1766\nInternational Journal of Engineering Research & Technology (IJERT)\nVol. 3 Issue 2, February - 2014\nIJERT\nIJERT\nISSN: 2278-0181\nwww.ijert.org\nIJERTV3IS20384\n\n\n \nsimplicity with which it is calibrated. Most software \norganizations, regardless of  maturity level can easily collect \nsize, effort and duration (time) for past projects. Process \nProductivity, being  exponential in nature is typically converted \nto a linear productivity index an organization can use to track \ntheir own changes in productivity and apply in future effort \nestimates. [2] Why this model is not widely accepted? One \nsignificant problem with the PUTNAM model is that it is based \non knowing, or being able to estimate accurately, the size (in \nlines of code) of the software to be developed. There is often \ngreat uncertainty in the software size. It may result in the \ninaccuracy of cost estimation. The error percentage of SLIM, a \nPutnam model based method, is 72.87%. \n \nThe ESTIMACS model was developed by Howard Rubin of \nHunter College as an outgrowth of a consulting assignment to \nEquitable Life. It is a proprietary system and, at the time the data \nwere collected, was marketed by Management and Computer \nServices (MACS). Since it is a proprietary model, details, such \nas the equations used, are not available. The model does not \nrequire \n \n \nSLOC as an input, relying instead on “Function-Point-like” \nmeasures. The research in this paper is based on Rubin’s paper \nfrom the 1983 IEEE conference on software development tools \nand the documentation provided by MACS [ZO, 221. The 25 \nESTIMACS input questions are described in these documents. \nThe ESTIMACS average error is 85 percent, which includes \nsome over and some under estimates, and is the smallest average \nerror of the four models. [7] \n \nThere is a brief discussion given below how the SEER-SEM \nmodel gone through its development stages and which version is \ncurrently in use. SEER-SEM model has made its unique way in \nsoftware cost estimation process. \n \nVersion 1.0: In 1988, Galorath Incorporated began work on the \ninitial version of SEER-SEM which resulted in an initial \nsolution of 22,000 lines of code. SEER-SEM version 1.0 was \nreleased on 13 5.25\" floppy disks and was an early product \nrunning on Windows version 2. Designing SEER-SEM for \nWindows was considered risky as the operating system had yet \nto establish itself as a viable competitor to the current dominant \nOS, Microsoft's MS-DOS. However, the adoption of a \nWindows-based format proved to be worthwhile, allowing \nSEER-SEM to offer a much more intuitive user interface than \nwould have otherwise been available in \nMS-DOS. Galorath chose Windows due to the ability to provide \na more graphical user environment, allowing more robust \nmanagement tradeoffs and understanding of what drives \nsoftware projects. \nNext Versions: Since that initial release in 1988, SEER-SEM \nhas undergone numerous upgrades, keeping up with changing \ntechnology, adapting to better meet the needs of the customer, \nand altering the model to achieve more precise estimates. For \nexample, the 1994 release of SEER-SEM version 4 included \nmajor enhancements to the core math behind the model, \nhandling the realities of projects rather than just a Rayleigh \ncurve approximation, as well as dozens more knowledge bases \nand the latest research in software science and complexity \nmetrics. 2003 saw SEER-SEM add significant new features such \nas Goal Setting and Risk Tuning. Both features operated as their \nnames suggest with Risk Analysis allowing project managers to \nmake changes to estimates and Goal Setting allowing for \nprojects to not only be estimated, but also to be managed. \nVersion 6 of SEER for Software was the first to be fully \nCOM-enabled, allowing SEER to both input and output through \nvarious Microsoft products, such as Excel. Version 7 included \nbetter handling of projects that stretch beyond their optimal \neffort. [9] \n \nCurrent Version: SEER for Software Version 7.3 is a vast \nimprovement over the original implementation, representing \nperhaps the first time that any version of SEER could be \nintegrated to support all phases of a project's lifecycle. The size \nof the software has grown to over 200,000 source lines of code \nand shifted from simply a means to generate work estimates \nthrough parametric modeling to a system that buttresses those \nresults with simulation-based probability and over 20,000 \nhistorical cases to draw conclusions from. \n \nThe original SEER-SEM has also branched into: \n  \n \nSEER for Information Technology – SEER-IT \n\n– a version of SEER created to aid IT professionals \nestimates the design, build, and maintenance of \ninformation technology infrastructures and service \nmanagement projects.  \n\n\n \nSEER for Hardware, Electronics, & Systems – \nSEER-H – a version of SEER designed to aid in the \nlife-cycle cost estimation of any type of hardware, \nelectronics or system. \n\n\n \nSEER for Manufacturing – SEER-MFG – a version of \nSEER tailored for estimating the detailed production \ncosts of manufacture, covering a wide range of \nstate-of-practice \nmanufacturing \nprocess \nknowledge.[10] \n \n \n \n \n \n1767\nInternational Journal of Engineering Research & Technology (IJERT)\nVol. 3 Issue 2, February - 2014\nIJERT\nIJERT\nISSN: 2278-0181\nwww.ijert.org\nIJERTV3IS20384\n\n\n \n  \n                                                                                                                                                          \n \nTable 1 Comparison of various Cost Estimation Models\n \nV. \nFUTURE SCOPE  \n \nHere, we have carried out the comparative systematic study of \nsome software cost estimation models in conjunction with \ntheir relevant techniques. Although, it would be awfully \ndifficult to say which model is preeminent as it is vastly based \non the size of software and certain other factors. But, largely \nCOCOMO-II is hugely used and has a broad prospect too. \n \nThus, we would like to carry out our future study on the same. \n \nVI. ACKNOWLEDGEMENT  \n \nThis paper has come out as a successful work product due to the \nthroughout support of our well-regarded teacher Mr. Gulzar \nAhmad (Assistant Professor).  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n]REFERENCES \n \n[1]  Ashita Malik, Varun Pandey, Anupama Kaushik et al.(2013), “Analysis of \nFuzzy Approaches for COCOMO II”, Vol-6, India, pp 68-75  \n[2]  Barry Boehm, Chris Abts, Sunita Chulan et al. (2000), “Software \nDevelopment Cost Estimation Approaches”, Annuals of Software \nEngineering, 10, pp 177-205 \n[3]  Barry Boehm, Chris Abts, Sunita Chulani et. al., “Software Development \nCost Estimation Approaches- A Survey”, IBM Research  \n[4] Roger S. Pressman, 1997 – Software Engineering – A Practitioner‟ s \nApproach, \nFourth \nEdition; \nhttp://groups.engin.umd.umich.edu/CIS/course.des/cis525/js/f00/gamel/\nhelp.html \n[5]  Sunita Devnani-Chulani et. al(May 1999), “Bayesian Analysis of \nSoftware Cost and Quality Models” \n[6]  Astha Dhiman, Chander Diwaker et. al(2013), “Optimization of \nCOCOMO II Effort Estimation using Generic Algorithm”  \n[7]  Raymond Madachay, Barry Boehm et. al(2008), “Comparative Analysis \nof COCOMO II, SEER-SEM and True-S Software Cost Models”  \n [8]  Sweta Kumari, Shashank Pushkar et. Al(2013), “Performance Analysis of \nSoftware Cost Estimation Methods: A Review”  \n[9]  Galorath, D & Evans M. (2006) Software Sizing, Estimation, and Risk \nManagement ISBN 0-8493-3593-0 \n \nS. \nYear of \nParameters \nModel Name \nAuthor \nTechnique Used \nNo. \nPublishing \nExtensibility \nFlexibility \nTraceability \nEasy to \nImplement \nBeing \n01. \nESTIMACS \nHoward \n1970 \nFunction Point \n√ \n√ \nproprietary, \nRubin \n(AT) \naccessibility is \nless \nPUTNAM‟ s \nBallpark Technique \nL.H. \n(NAT), \n02. \nS/w Life Cycle \n1978 \n√ \nPutnam, \nFunction Point \n√ \nModel(SLIM) \n(AT), \n03. \nCOCOMO \nBarry \n1981 \nSLOC‟ s, KDSI \n√ \n√ \n81[3][4][5][6] \nBoehm \nTop-down, bottom- \nSuitable for \n04 \nSEER-SAM \nGalorth \n1983 \n√ \n√ \n√ \nSLC over \nup \n2,00,000 \nUSC-CSE & \nCOCOMO \nObject Point, \nSuitable for \nII Project \nCOCOMO II \n1995 \nFunction Point, \n√ \n√ \nlarge size \n05. \nAffiliate \nSLOCs, KSLOC \nprojects \nOrganizations \n \n1768\nInternational Journal of Engineering Research & Technology (IJERT)\nVol. 3 Issue 2, February - 2014\nIJERT\nIJERT\nISSN: 2278-0181\nwww.ijert.org\nIJERTV3IS20384\n",
  "metadata": {
    "filename": "software-cost-estimation-models-and-techniques-a-survey-IJERTV3IS20384.pdf",
    "num_pages": 6,
    "title": "Software Cost Estimation Models and Techniques: A Survey",
    "author": "Yansi Keim, Manish Bhardwaj, Shashank Saroop, Aditya Tandon",
    "subject": "IJERT.COM - International Journal of Engineering Research and Technology"
  },
  "num_pages": 6,
  "timestamp": "2025-11-13T02:00:03.897878"
}